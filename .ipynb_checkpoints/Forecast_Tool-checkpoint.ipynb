{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a710f3",
   "metadata": {
    "id": "f7a710f3"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import trino\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d45a6",
   "metadata": {
    "id": "912d45a6",
    "outputId": "8a86fd36-1678-48d8-969e-3c02c3cddd72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glovo\\AppData\\Local\\Temp\\ipykernel_16028\\2617929161.py:61: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  expected_couriers = pd.read_sql_query(expected_query, conn)\n",
      "C:\\Users\\Glovo\\AppData\\Local\\Temp\\ipykernel_16028\\2617929161.py:62: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  active_couriers = pd.read_sql_query(active_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_data</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>city_code</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>active_couriers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>22:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>22:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21919</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>01:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21920</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>01:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21921</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>00:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21922</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>00:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21923</th>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Mon</td>\n",
       "      <td>00:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21924 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_data weekday hour_data city_code  expected_couriers  \\\n",
       "0     2022-11-01     Tue     23:00       SFX                0.0   \n",
       "1     2022-11-01     Tue     23:00       SOU                0.0   \n",
       "2     2022-11-01     Tue     23:00       TIS               26.0   \n",
       "3     2022-11-01     Tue     22:00       SFX                2.0   \n",
       "4     2022-11-01     Tue     22:00       SOU                4.0   \n",
       "...          ...     ...       ...       ...                ...   \n",
       "21919 2023-12-11     Mon     01:00       SOU                0.0   \n",
       "21920 2023-12-11     Mon     01:00       TIS               41.0   \n",
       "21921 2023-12-11     Mon     00:00       SFX                4.0   \n",
       "21922 2023-12-11     Mon     00:00       SOU                8.0   \n",
       "21923 2023-12-11     Mon     00:00       TIS               77.0   \n",
       "\n",
       "       active_couriers  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                 19.0  \n",
       "3                  3.0  \n",
       "4                  2.0  \n",
       "...                ...  \n",
       "21919              NaN  \n",
       "21920              NaN  \n",
       "21921              NaN  \n",
       "21922              NaN  \n",
       "21923              NaN  \n",
       "\n",
       "[21924 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Get the time parameters ##########################\n",
    "\n",
    "today = date.today()\n",
    "yesterday = today - timedelta(days = 1)\n",
    "tomorrow = today + timedelta(days = 1)\n",
    "city = \"TIS\"\n",
    "########################### Get the city parameters ###########################\n",
    "\n",
    "# Get the city urls\n",
    "if city == \"TIS\":\n",
    "    url_historical_tis = \"https://archive-api.open-meteo.com/v1/archive?latitude=36.7498325&longitude=10.2676506&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred_tis = \"https://api.open-meteo.com/v1/forecast?latitude=36.7498325&longitude=10.2676506&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "elif city == \"SOU\":\n",
    "    url_historical_sou = \"https://archive-api.open-meteo.com/v1/archive?latitude=35.8059273&longitude=10.6488785&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred_sou = \"https://api.open-meteo.com/v1/forecast?latitude=35.8059273&longitude=10.6488785&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "elif city == \"SFX\":\n",
    "    url_historical_sfx = \"https://archive-api.open-meteo.com/v1/archive?latitude=35.0177587&longitude=10.5943665&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred_sfx = \"https://api.open-meteo.com/v1/forecast?latitude=35.0177587&longitude=10.5943665&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "\n",
    "# Get the city model\n",
    "if city == \"TIS\":\n",
    "    model_pkl_file = \"model_tis.pkl\"\n",
    "elif city == \"SOU\":\n",
    "    model_pkl_file = \"model_sou.pkl\"\n",
    "elif city == \"SFX\":\n",
    "    model_pkl_file = \"model_sfx.pkl\"\n",
    "\n",
    "########################### set up the connection ###########################\n",
    "\n",
    "# you need not change these\n",
    "HOST = 'starburst.g8s-data-platform-prod.glovoint.com'\n",
    "PORT = 443\n",
    "\n",
    "# prepare your query, this will\n",
    "# list all columns in the Customer Behaviour Data Product\n",
    "expected_query = '''\n",
    "SELECT\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at ,'%Y-%m-%d') AS \"date_data\",\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%a') AS weekday,\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%H:%i') AS \"hour_data\",\n",
    "    cities_v2.city_code AS \"city_code\",\n",
    "    SUM(capacity_changes_slot_level.couriers_expected) AS \"expected_couriers\"\n",
    "FROM delta.courier_forecasting_odp.capacity_changes_slot_level  AS capacity_changes_slot_level\n",
    "LEFT JOIN delta.central_geography_odp.cities_v2  AS cities_v2 ON capacity_changes_slot_level.city_code = cities_v2.city_code\n",
    "WHERE\n",
    " DATE(capacity_changes_slot_level.scheduling_slot_started_local_at) >= DATE('2022-11-01')\n",
    "AND DATE(capacity_changes_slot_level.scheduling_slot_started_local_at) < DATE(DATE_ADD('day',2,CURRENT_DATE))\n",
    "AND cities_v2.country_code = 'TN'\n",
    "AND DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%H:%i') NOT IN ('03:00','04:00','05:00','06:00','07:00','08:00')\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY 1,2,3 DESC,4\n",
    "'''\n",
    "active_query = '''\n",
    "SELECT\n",
    "    DATE(ss.scheduling_slot_started_local_at) AS date_data,\n",
    "    DATE_FORMAT(ss.scheduling_slot_started_local_at, '%a') AS weekday,\n",
    "    DATE_FORMAT(ss.scheduling_slot_started_local_at, '%H:%i') AS hour_data,\n",
    "    kpi_orders.order_city_code AS city_code,\n",
    "    -- active couriers\n",
    "    COUNT(DISTINCT CASE WHEN kpi_orders.order_final_status='DeliveredStatus' THEN kpi_orders.courier_id ELSE NULL END) AS active_couriers\n",
    "\n",
    "FROM delta.central_order_descriptors_odp.order_descriptors_v2 kpi_orders\n",
    "    LEFT JOIN delta.courier_dispatching_engine_odp.order_slot_zone_master slot_zone ON slot_zone.order_id = kpi_orders.order_id\n",
    "    LEFT JOIN delta.courier_logistics_scheduling_odp.scheduling_slots ss ON ss.scheduling_slot_id = slot_zone.scheduling_slot_id\n",
    "    LEFT JOIN delta.courier_order_flow_odp.delivery_times_logistics_order_level_attributes dt_info ON dt_info.order_id = kpi_orders.order_id\n",
    "    LEFT JOIN delta.courier_core_cpo_odp.order_level_v2 cpo ON cpo.order_id=kpi_orders.order_id\n",
    "WHERE slot_zone.order_city_code IN ('TIS','SFX','SOU')\n",
    "    AND DATE(ss.scheduling_slot_started_local_at) >= DATE('2022-11-01')\n",
    "    AND DATE(ss.scheduling_slot_started_local_at) < CURRENT_DATE\n",
    "    AND kpi_orders.order_handling_strategy='GEN2'\n",
    "    AND DATE_FORMAT(ss.scheduling_slot_started_local_at, '%H:%i') NOT IN ('03:00','04:00','05:00','06:00','07:00','08:00')\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY 1,2,3 DESC,4\n",
    "'''\n",
    "\n",
    "conn_details = {\n",
    "    'host': HOST,\n",
    "    'port': PORT,\n",
    "    'http_scheme': 'https',\n",
    "    'auth': trino.auth.OAuth2Authentication()\n",
    "}\n",
    "\n",
    "\n",
    "# To export result to pandas\n",
    "with trino.dbapi.connect(**conn_details) as conn:\n",
    "\n",
    "    expected_couriers = pd.read_sql_query(expected_query, conn)\n",
    "    active_couriers = pd.read_sql_query(active_query, conn)\n",
    "\n",
    "########################### Process data to get training data and prediction data ###########################\n",
    "expected_couriers[\"date_data\"] = pd.to_datetime(expected_couriers[\"date_data\"])\n",
    "active_couriers[\"date_data\"] = pd.to_datetime(active_couriers[\"date_data\"])\n",
    "data = pd.merge(expected_couriers,active_couriers,on=[\"date_data\",'hour_data',\"weekday\",'city_code'],how=\"outer\")\n",
    "display(data)\n",
    "data_train = data[data[\"active_couriers\"].isna()==False].copy()\n",
    "data_predict = data[(data[\"active_couriers\"].isna()) & (pd.to_datetime(data[\"date_data\"]).dt.date>=today)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a1f0c",
   "metadata": {
    "id": "433a1f0c"
   },
   "outputs": [],
   "source": [
    "# Encoding functions to ensure consistency across training data and prediction data\n",
    "\n",
    "def encode_weekday(weekday):\n",
    "    weekdays = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    if weekday in weekdays:\n",
    "        return weekdays.index(weekday)\n",
    "    else:\n",
    "        assert(\"Verify that weekday is in the correct format ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\")\n",
    "\n",
    "def encode_match_range(match_range):\n",
    "    match_ranges = [\"national\",\"international\"]\n",
    "    if match_range in match_ranges:\n",
    "        return match_ranges.index(match_range)+1\n",
    "    else:\n",
    "        assert('Verify that match_range is in the correct format [\"national\",\"international\"]')\n",
    "\n",
    "def encode_match_type(match_type):\n",
    "    match_types = [\"league\",\"cup\",\"final\",\"friendly\"]\n",
    "    if match_type in match_types:\n",
    "        return match_types.index(match_type)+1\n",
    "    else:\n",
    "        assert('Verify that match_type is in the correct format [\"league\",\"cup\",\"final\",\"friendly\"]')\n",
    "\n",
    "def encode_event_type(event_type):\n",
    "    event_types = [\"sudden_event\",\"expected_event\"]\n",
    "    if event_type in event_types:\n",
    "        return event_types.index(event_type)+1\n",
    "    else:\n",
    "        assert('Verify that event_type is in the correct format [\"sudden_event\",\"expected_event\"]')\n",
    "\n",
    "\n",
    "def encode_event_category(event_category):\n",
    "    event_categorys = [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]\n",
    "    if event_category in event_categorys:\n",
    "        return event_categorys.index(event_category)+1\n",
    "    else:\n",
    "        assert('Verify that event_category is in the correct format [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]')\n",
    "\n",
    "def encode_event_range(event_range):\n",
    "    event_ranges = [\"local\",\"regional\",\"national\",\"international\"]\n",
    "    if event_range in event_ranges:\n",
    "        return event_ranges.index(event_range)+1\n",
    "    else:\n",
    "        assert('Verify that event_range is in the correct format [\"local\",\"regional\",\"national\",\"international\"]')\n",
    "\n",
    "def encode_event_impact(event_impact):\n",
    "    event_impacts = [\"national\",\"international\"]\n",
    "    if event_impact in event_impacts:\n",
    "        return event_impacts.index(event_impact)+1\n",
    "    else:\n",
    "        assert('Verify that event_impact is in the correct format [\"small\",\"moderate\",\"big\"]')\n",
    "\n",
    "def encode_hour_data(hour_data):\n",
    "    hours = [\"09:00\",\"10:00\",\"11:00\",\"12:00\",\"13:00\",\"14:00\",\"15:00\",\"16:00\",\"17:00\",\"18:00\",\"19:00\",\"20:00\",\"21:00\",\"22:00\",\"23:00\",\"00:00\",\"01:00\"]\n",
    "    if hour_data in hours:\n",
    "        return hours.index(hour_data)+1\n",
    "    else:\n",
    "        assert('Verify that hour_data is in the correct format hh:mm ')\n",
    "\n",
    "def get_special_events():\n",
    "    special_events_rows = []\n",
    "    football_matches_rows = []\n",
    "    conti = \"y\"\n",
    "    while conti==\"y\":\n",
    "        event = input('Enter event, choose from [\"f\" for football match,\"e\" for other events]: ')\n",
    "        if event == \"f\":\n",
    "            match_range= input('Enter match type, choose from [\"national\",\"international\"]: ')\n",
    "            match_type = input('Enter match type, choose from [\"league\",\"cup\",\"final\",\"friendly\"]: ')\n",
    "            match_date = input('Enter match date, use this format \"dd-mm-yyyy\" : ')\n",
    "            match_start_hour = input('Enter match start hour, use this format \"hh:00\" : ')\n",
    "            match_city = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "            for i in range(-1,3,1):\n",
    "                if match_city ==\"ALL\":\n",
    "                    for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                        football_matches_row = []\n",
    "                        football_matches_row.append(match_date)\n",
    "                        football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "                        football_matches_row.append(match_range)\n",
    "                        football_matches_row.append(match_type)\n",
    "                        football_matches_row.append(city)\n",
    "                        football_matches_rows.append(football_matches_row)\n",
    "                else:\n",
    "                    city = match_city\n",
    "                    football_matches_row = []\n",
    "                    football_matches_row.append(match_date)\n",
    "                    football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "                    football_matches_row.append(match_range)\n",
    "                    football_matches_row.append(match_type)\n",
    "                    football_matches_row.append(city)\n",
    "                    football_matches_rows.append(football_matches_row)\n",
    "        else:\n",
    "            special_events_row = []\n",
    "            event_type = input('Enter event type, choose from [\"sudden_event\",\"expected_event\"]: ')\n",
    "            event_category = input('Enter event category, choose from [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]: ')\n",
    "            event_range = input('Enter event range, choose from [\"local\",\"regional\",\"national\",\"international\"]: ')\n",
    "            event_impact = input('Enter event impact, choose from [\"small\",\"moderate\",\"big\"]: ')\n",
    "            event_date = input('Enter event date, use this format \"dd-mm-yyyy\" : ')\n",
    "            event_start_hour = input('Enter event start hour, use this format \"hh:00\" : ')\n",
    "            event_duration = input('Enter event duration, use this format \"hh\" : ')\n",
    "            event_city_code = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "            special_events_row.append(event_type)\n",
    "            special_events_row.append(event_category)\n",
    "            special_events_row.append(event_range)\n",
    "            special_events_row.append(event_impact)\n",
    "            special_events_row.append(event_date)\n",
    "            special_events_row.append(event_start_hour)\n",
    "            special_events_row.append(event_duration)\n",
    "            special_events_row.append(event_city_code)\n",
    "            special_events_rows.append(special_events_row)\n",
    "        conti = input('add another event ? y/n: ')\n",
    "\n",
    "    special_events_final_rows = []\n",
    "    for cells in special_events_rows:\n",
    "        duration = int(cells[6].split(\":\")[0])\n",
    "        for i in range(duration):\n",
    "            if cells[7]==\"ALL\":\n",
    "                for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                    ser= []\n",
    "                    hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "                    ser.append(cells[4])\n",
    "                    ser.append(hour)\n",
    "                    ser.append(city)\n",
    "                    ser.append(cells[0])\n",
    "                    ser.append(cells[1])\n",
    "                    ser.append(cells[2])\n",
    "                    ser.append(cells[3])\n",
    "                    special_events_final_rows.append(ser)\n",
    "            else:\n",
    "                ser= []\n",
    "                city = cells[7]\n",
    "                hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "                ser.append(cells[4])\n",
    "                ser.append(hour)\n",
    "                ser.append(city)\n",
    "                ser.append(cells[0])\n",
    "                ser.append(cells[1])\n",
    "                ser.append(cells[2])\n",
    "                ser.append(cells[3])\n",
    "                special_events_final_rows.append(ser)\n",
    "\n",
    "    special_events_df = pd.DataFrame(special_events_final_rows)\n",
    "    special_events_df.rename(columns={0:\"date_data\",1:\"hour_data\",2:\"city_code\",3:\"event_type\",4:\"event_category\",5:\"event_range\",6:\"event_impact\"},inplace=True)\n",
    "    football_matches_df = pd.DataFrame(football_matches_rows)\n",
    "    football_matches_df[\"match_range\"] = football_matches_df[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "    football_matches_df[\"match_type\"] = football_matches_df[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "    football_matches_df.sort_values([\"date_data\",\"city_code\",\"hour_data\",\"match_range\",\"match_type\"], inplace=True, ascending=[True,True,True,False,False])\n",
    "    football_matches_df.drop_duplicates(subset = [\"date_data\",\"hour_data\",\"city_code\"], keep = \"first\", inplace=True)\n",
    "    football_matches_df.rename(columns={0:\"date_data\",1:\"hour_data\",3:\"match_type\",2:\"match_range\",4:\"city_code\"},inplace=True)\n",
    "    final_df = pd.merge(football_matches_df,special_events_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"outer\")\n",
    "    final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "    final_df[\"hour_data\"] = final_df[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e125f05",
   "metadata": {
    "id": "8e125f05",
    "outputId": "da27dbb1-42cd-4de5-ac3b-837a5b9b7dd9",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>weekday</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>55.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>161.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>60.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>67.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>88.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>84.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6726 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      relativehumidity_2m  apparent_temperature  rain  cloudcover  wind_speed  \\\n",
       "0                    69.0                  16.5   0.0         1.0        18.8   \n",
       "1                    79.0                  17.8   0.0         0.0        18.0   \n",
       "2                    77.0                  21.2   0.0         0.0        20.4   \n",
       "3                    76.0                  21.4   0.0         0.0        23.2   \n",
       "4                    71.0                  21.4   0.0         0.0        25.2   \n",
       "...                   ...                   ...   ...         ...         ...   \n",
       "6751                 55.0                  15.5   0.0        45.0        13.4   \n",
       "6752                 60.0                  14.6   0.0        55.0        15.6   \n",
       "6753                 67.0                  13.4   0.0        33.0        14.4   \n",
       "6754                 88.0                   7.6   0.0        20.0        15.5   \n",
       "6755                 84.0                   7.9   0.0         1.0        21.9   \n",
       "\n",
       "      hour_data  weekday  expected_couriers  month  \n",
       "0            16        1               26.0     11  \n",
       "1            15        1               46.0     11  \n",
       "2            14        1               58.0     11  \n",
       "3            13        1               59.0     11  \n",
       "4            12        1               57.0     11  \n",
       "...         ...      ...                ...    ...  \n",
       "6751          4        4              161.0     12  \n",
       "6752          3        4               33.0     12  \n",
       "6753          2        4               18.0     12  \n",
       "6754          1        4               51.0     12  \n",
       "6755          0        4               87.0     12  \n",
       "\n",
       "[6726 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree R-squared score (test): 0.873\n",
      "tree Mean squared error: 1570.381\n",
      "tree Mean absolute error: 24.378\n"
     ]
    }
   ],
   "source": [
    "######################################## Training Process ########################################\n",
    "\n",
    "# Get the data train for the city\n",
    "city_data_train = data_train[data_train[\"city_code\"]==city].copy()\n",
    "\n",
    "########################### Process the data to prepare it for modeling ###########################\n",
    "\n",
    "#### Prepare Weather Data\n",
    "\n",
    "# Load and process weather data for the city\n",
    "\n",
    "historical_response = requests.get(url_historical)\n",
    "data_historical = json.loads(historical_response.content)\n",
    "weather_data = pd.DataFrame(data_historical[\"hourly\"])\n",
    "weather_data[\"date_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[0])\n",
    "weather_data[\"hour_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[1])\n",
    "weather_data[\"city_code\"] = city\n",
    "weather_data[\"hour_data\"] = weather_data[\"hour_data\"].apply(lambda x: x if x not in [\"02:00\",\"03:00\",\"04:00\",\"05:00\",\"06:00\",\"07:00\",\"08:00\"] else None)\n",
    "weather_data[\"date_data\"] = pd.to_datetime(weather_data[\"date_data\"])\n",
    "weather_data = weather_data.dropna()\n",
    "# Drop rows from weather_data with dates higher than those in data_train\n",
    "weather_data = weather_data[(pd.to_datetime(weather_data[\"date_data\"])<=pd.to_datetime(data_train[\"date_data\"].max()))].reset_index(drop=True)\n",
    "weather_data = weather_data.sort_values(['date_data', 'hour_data','city_code'],ascending = [True, False, True]).reset_index(drop=True)\n",
    "# Merge the dfs and keep processing\n",
    "city_data_train = pd.merge(weather_data,data_train,on=['date_data', 'hour_data','city_code'])\n",
    "city_data_train[\"month\"] = city_data_train[\"date_data\"].apply(lambda x:int(str(x).split(\"-\")[1]))\n",
    "city_data_train[\"hour_data\"] = city_data_train[\"hour_data\"].astype(\"category\").cat.codes\n",
    "city_data_train[\"weekday\"] = city_data_train[\"weekday\"].apply(encode_weekday)\n",
    "# drop unnacessary rows and columns\n",
    "city_data_train.rename(columns={\"winddirection_100m\":\"wind_direction\",\"windspeed_100m\":\"wind_speed\"},inplace=True)\n",
    "city_data_train.dropna()\n",
    "city_data_train = city_data_train[city_data_train[\"active_couriers\"] >1]\n",
    "\n",
    "#### Prepare special events data\n",
    "\n",
    "final_df = pd.read_csv(\"special_events_historical.csv\")\n",
    "final_df = final_df.iloc[: , 1:]\n",
    "city_data_train.merge(final_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"left\")\n",
    "city_data_train[\"match_range\"] = city_data_train[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "city_data_train[\"match_type\"] = city_data_train[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "city_data_train[\"event_type\"] = city_data_train[\"event_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_type(x))\n",
    "city_data_train[\"event_category\"] = city_data_train[\"event_category\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_category(x))\n",
    "city_data_train[\"event_range\"] = city_data_train[\"event_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_range(x))\n",
    "city_data_train[\"event_impact\"] = city_data_train[\"event_impact\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_impact(x))\n",
    "\n",
    "########################### Train Model ###########################\n",
    "\n",
    "y = city_data_train[\"active_couriers\"]\n",
    "X = city_data_train.drop([\"temperature_2m\",\"active_couriers\",\"precipitation\",\"time\",\"date_data\",\"is_day\",\"city_code\",\"wind_direction\"],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20)\n",
    "display(X)\n",
    "regressor = DecisionTreeRegressor(criterion=\"poisson\",splitter = \"best\",max_depth = 10).fit(X_train, np.log(y_train))\n",
    "regressor_pred = np.round(np.exp(regressor.predict(X_test)),0)\n",
    "\n",
    "########################### Print results ###########################\n",
    "\n",
    "print('tree R-squared score (test): {:.3f}'.format(regressor.score(X_test, np.log(y_test))))\n",
    "print('tree Mean squared error: {:.3f}'.format(mean_squared_error(y_test, regressor_pred)))\n",
    "print('tree Mean absolute error: {:.3f}'.format(mean_absolute_error(y_test, regressor_pred)))\n",
    "\n",
    "########################### Save the model ###########################\n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:\n",
    "    pickle.dump(regressor, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79726487",
   "metadata": {
    "id": "79726487",
    "outputId": "7be01763-0aad-46e9-cad0-48af7e62fc17",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation_probability</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>wind speed</th>\n",
       "      <th>wind direction</th>\n",
       "      <th>is_day</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>city_code</th>\n",
       "      <th>weekday</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>active_couriers</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.91</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>16.3</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>23.2</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>189.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>30.2</td>\n",
       "      <td>287</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>32.4</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>372.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>33.2</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.82</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>33.7</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>35.9</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>37.2</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>39.7</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>41.3</td>\n",
       "      <td>302</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>40.8</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>44.1</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>41.8</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>28.4</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>26.1</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>37</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>20.6</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.86</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>22.2</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.6</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.5</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>15.1</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>15.1</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.2</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.9</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12.2</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.69</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13.5</td>\n",
       "      <td>241</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.4</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.57</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.4</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.54</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>17.7</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.55</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.6</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.59</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.2</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.63</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.9</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.69</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.5</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.92</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>17.2</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.93</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>18.0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    precipitation_probability  temperature_2m  relativehumidity_2m  \\\n",
       "0                           0            14.8                 0.91   \n",
       "1                           0            15.3                 0.87   \n",
       "2                           0            15.8                 0.83   \n",
       "3                           0            16.0                 0.82   \n",
       "4                           0            16.2                 0.83   \n",
       "5                           0            16.4                 0.82   \n",
       "6                           0            16.9                 0.80   \n",
       "7                           0            17.7                 0.75   \n",
       "8                           0            18.8                 0.69   \n",
       "9                           0            19.6                 0.65   \n",
       "10                          0            19.4                 0.64   \n",
       "11                          0            19.6                 0.61   \n",
       "12                          0            18.5                 0.65   \n",
       "13                          0            17.1                 0.70   \n",
       "14                          0            15.1                 0.76   \n",
       "15                         37            13.4                 0.83   \n",
       "16                         55            13.9                 0.86   \n",
       "17                          0            13.5                 0.89   \n",
       "18                          0            13.8                 0.90   \n",
       "19                          0            14.1                 0.89   \n",
       "20                          0            14.7                 0.86   \n",
       "21                          0            15.3                 0.84   \n",
       "22                          0            16.1                 0.81   \n",
       "23                          0            17.2                 0.76   \n",
       "24                          0            18.6                 0.69   \n",
       "25                          0            19.9                 0.62   \n",
       "26                          0            20.3                 0.57   \n",
       "27                          0            20.4                 0.54   \n",
       "28                          0            20.2                 0.55   \n",
       "29                          0            19.3                 0.59   \n",
       "30                          0            17.9                 0.63   \n",
       "31                          0            16.2                 0.69   \n",
       "32                          0            14.2                 0.92   \n",
       "33                          0            14.4                 0.93   \n",
       "\n",
       "    apparent_temperature  rain  cloudcover  wind speed  wind direction  \\\n",
       "0                   14.9   0.0        0.56        16.3             264   \n",
       "1                   15.0   0.0        0.37        23.2             282   \n",
       "2                   14.8   0.0        0.02        30.2             287   \n",
       "3                   14.9   0.0        0.04        32.4             293   \n",
       "4                   15.2   0.0        0.83        33.2             300   \n",
       "5                   15.3   0.0        1.00        33.7             299   \n",
       "6                   15.6   0.0        1.00        35.9             297   \n",
       "7                   16.1   0.0        0.39        37.2             298   \n",
       "8                   17.0   0.0        0.43        39.7             301   \n",
       "9                   17.5   0.0        0.37        41.3             302   \n",
       "10                  17.2   0.0        0.36        40.8             289   \n",
       "11                  17.0   0.0        0.30        44.1             290   \n",
       "12                  16.0   0.0        0.36        41.8             287   \n",
       "13                  15.4   0.0        0.57        28.4             270   \n",
       "14                  13.4   0.0        0.56        26.1             252   \n",
       "15                  12.3   0.0        0.18        20.6             275   \n",
       "16                  13.0   0.0        0.78        22.2             278   \n",
       "17                  13.3   0.0        0.00        16.6             231   \n",
       "18                  13.8   0.0        0.00        15.5             226   \n",
       "19                  14.2   0.0        0.22        15.1             218   \n",
       "20                  14.8   0.0        0.24        15.1             230   \n",
       "21                  15.4   0.0        1.00        14.2             234   \n",
       "22                  16.3   0.0        1.00        12.9             234   \n",
       "23                  17.6   0.0        1.00        12.2             236   \n",
       "24                  18.7   0.0        0.90        13.5             241   \n",
       "25                  19.5   0.0        0.52        15.4             254   \n",
       "26                  19.3   0.0        0.00        17.4             257   \n",
       "27                  19.1   0.0        0.10        17.7             258   \n",
       "28                  19.0   0.0        0.10        15.6             251   \n",
       "29                  18.3   0.0        0.00        14.2             240   \n",
       "30                  17.0   0.0        0.00        12.9             234   \n",
       "31                  15.4   0.0        0.00        13.5             236   \n",
       "32                  14.2   0.0        0.52        17.2             244   \n",
       "33                  14.5   0.0        0.55        18.0             254   \n",
       "\n",
       "    is_day  hour_data  city_code  weekday  expected_couriers  active_couriers  \\\n",
       "0        0         16          0        1              103.0              NaN   \n",
       "1        0         15          0        1              189.0              NaN   \n",
       "2        0         14          0        1              275.0              NaN   \n",
       "3        0         13          0        1              372.0              NaN   \n",
       "4        0         12          0        1              367.0              NaN   \n",
       "5        0         11          0        1              300.0              NaN   \n",
       "6        0         10          0        1              185.0              NaN   \n",
       "7        1          9          0        1              177.0              NaN   \n",
       "8        1          8          0        1              171.0              NaN   \n",
       "9        1          7          0        1              223.0              NaN   \n",
       "10       1          6          0        1              224.0              NaN   \n",
       "11       1          5          0        1              151.0              NaN   \n",
       "12       1          4          0        1               72.0              NaN   \n",
       "13       1          3          0        1               40.0              NaN   \n",
       "14       1          2          0        1               23.0              NaN   \n",
       "15       0          1          0        1               70.0              NaN   \n",
       "16       0          0          0        1              107.0              NaN   \n",
       "17       0         16          0        0              105.0              NaN   \n",
       "18       0         15          0        0              170.0              NaN   \n",
       "19       0         14          0        0              207.0              NaN   \n",
       "20       0         13          0        0              262.0              NaN   \n",
       "21       0         12          0        0              272.0              NaN   \n",
       "22       0         11          0        0              247.0              NaN   \n",
       "23       0         10          0        0              163.0              NaN   \n",
       "24       1          9          0        0              121.0              NaN   \n",
       "25       1          8          0        0              123.0              NaN   \n",
       "26       1          7          0        0              177.0              NaN   \n",
       "27       1          6          0        0              254.0              NaN   \n",
       "28       1          5          0        0              290.0              NaN   \n",
       "29       1          4          0        0              112.0              NaN   \n",
       "30       1          3          0        0               28.0              NaN   \n",
       "31       1          2          0        0               21.0              NaN   \n",
       "32       0          1          0        0               41.0              NaN   \n",
       "33       0          0          0        0               77.0              NaN   \n",
       "\n",
       "   month  year  \n",
       "0     12     1  \n",
       "1     12     1  \n",
       "2     12     1  \n",
       "3     12     1  \n",
       "4     12     1  \n",
       "5     12     1  \n",
       "6     12     1  \n",
       "7     12     1  \n",
       "8     12     1  \n",
       "9     12     1  \n",
       "10    12     1  \n",
       "11    12     1  \n",
       "12    12     1  \n",
       "13    12     1  \n",
       "14    12     1  \n",
       "15    12     1  \n",
       "16    12     1  \n",
       "17    12     1  \n",
       "18    12     1  \n",
       "19    12     1  \n",
       "20    12     1  \n",
       "21    12     1  \n",
       "22    12     1  \n",
       "23    12     1  \n",
       "24    12     1  \n",
       "25    12     1  \n",
       "26    12     1  \n",
       "27    12     1  \n",
       "28    12     1  \n",
       "29    12     1  \n",
       "30    12     1  \n",
       "31    12     1  \n",
       "32    12     1  \n",
       "33    12     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['precipitation', 'time', 'date_data'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m regressor\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m################## make predictions and display results ####################\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data_predict_tis\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_couriers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_day\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhour_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweekday\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# preds = model.predict(data_test.drop([\"time\",\"precipitation_probability\"],axis=1))\u001b[39;00m\n\u001b[0;32m     37\u001b[0m data_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive_couriers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(preds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['precipitation', 'time', 'date_data'] not found in axis\""
     ]
    }
   ],
   "source": [
    "######################################## Prediction Process ########################################\n",
    "\n",
    "# Get the data pedict for the city\n",
    "city_data_predict = city_data_predict[city_data_predict[\"city_code\"]==city].copy()\n",
    "\n",
    "########################### Process the data to prepare it for modeling ###########################\n",
    "\n",
    "#### Prepare Weather Data\n",
    "\n",
    "# Load weather data for the city\n",
    "pred_response = requests.get(url_pred)\n",
    "data_pred = json.loads(pred_response.content)\n",
    "weather_data = pd.DataFrame(data_pred[\"hourly\"])\n",
    "weather_data[\"date_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[0])\n",
    "weather_data[\"hour_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[1])\n",
    "weather_data[\"city_code\"] = city\n",
    "weather_data[\"hour_data\"] = weather_data[\"hour_data\"].apply(lambda x: x if x not in [\"02:00\",\"03:00\",\"04:00\",\"05:00\",\"06:00\",\"07:00\",\"08:00\"] else None)\n",
    "weather_data[\"date_data\"] = pd.to_datetime(weather_data[\"date_data\"])\n",
    "weather_data = weather_data.dropna()\n",
    "# Drop rows from weather_data with dates lower than those in city_data_predict\n",
    "weather_data = weather_data[(pd.to_datetime(weather_data[\"date_data\"])<=pd.to_datetime(city_data_predict[\"date_data\"].max()))].reset_index(drop=True)\n",
    "weather_data = weather_data.sort_values(['date_data', 'hour_data','city_code'],ascending = [True, False, True]).reset_index(drop=True)\n",
    "# Merge the dfs and keep processing\n",
    "city_data_predict = pd.merge(weather_data,city_data_predict,on=['date_data', 'hour_data','city_code'])\n",
    "city_data_predict[\"month\"] = city_data_predict[\"date_data\"].apply(lambda x:int(str(x).split(\"-\")[1]))\n",
    "city_data_predict[\"hour_data\"] = city_data_predict[\"hour_data\"].astype(\"category\").cat.codes\n",
    "city_data_predict[\"weekday\"] = city_data_predict[\"weekday\"].apply(encode_weekday)\n",
    "# drop unnacessary rows and columns\n",
    "city_data_predict.rename(columns={\"winddirection_80m\":\"wind direction\",\"windspeed_80m\":\"wind speed\"},inplace=True)\n",
    "city_data_predict.drop([\"precipitation\",\"time\",\"date_data\"],inplace=True,axis=1)\n",
    "\n",
    "#### Prepare special events data\n",
    "\n",
    "final_df = get_special_events()\n",
    "city_data_predict.merge(final_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"left\")\n",
    "city_data_predict[\"match_range\"] = city_data_predict[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "city_data_predict[\"match_type\"] = city_data_predict[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "city_data_predict[\"event_type\"] = city_data_predict[\"event_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_type(x))\n",
    "city_data_predict[\"event_category\"] = city_data_predict[\"event_category\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_category(x))\n",
    "city_data_predict[\"event_range\"] = city_data_predict[\"event_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_range(x))\n",
    "city_data_predict[\"event_impact\"] = city_data_predict[\"event_impact\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_impact(x))\n",
    "\n",
    "################## make predictions and display results ####################\n",
    "\n",
    "# Load Model\n",
    "with open(model_pkl_file, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Make predictions\n",
    "preds = np.exp(model.predict(city_data_predict.drop([\"precipitation_probability\",\"temperature_2m\",\"active_couriers\",\"precipitation\",\"time\",\"date_data\",\"is_day\",\"city_code\",\"wind_direction\"],axis=1)))\n",
    "data_test[\"active_couriers\"] = np.round(preds,0)\n",
    "display(data_test[[\"date_data\",\"hour_data\",\"weekday\",\"expected_couriers\",\"active_couriers\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9edadcb",
   "metadata": {
    "id": "c9edadcb",
    "outputId": "0205603f-1945-440c-d3a6-893932717c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guinea-Bissau', 'Central African Republic', 'Liberia', 'Borussia Dortmund', 'Ecuador', 'Equatorial Guinea', 'Cape Town City FC', 'RSB Berkane', 'Simba SC', 'Qatar', 'Germany', 'Libya', 'Bayern Munich', 'Jendouba Sport', 'Poland', 'Rejiche', 'South Korea', 'Club S Hammam-Lif', 'Ivory Coast', 'Rangers', 'Rivers United FC', 'Cape Verde', 'Future FC', 'Congo', 'Sudan', 'Ajax', 'Pyramids FC', 'Switzerland', 'FC Porto', 'Burkina Faso', 'Sevilla', 'Uganda', 'Bloemfontein Celtic', 'FC Koebenhavn', 'Niger', 'Jerba', 'Ben Arous', 'Maccabi Haifa', 'Comoros', 'Finland', 'Mauritania', 'Ethiopia', 'Celtic', 'Benfica', 'Kazakhstan', 'Netherlands', 'South Sudan', 'Burundi', 'Al Hilal Omdurman', 'Malawi', 'Tunisia', 'TP Mazembe', 'Gambia', 'Egypt', 'Canada', 'Shakhtar Donetsk', 'El Zamalek', 'Club Brugge', 'England', 'Stade Tunisien', 'South Africa', 'Guinea', 'RasenBallsport Leipzig', 'France', 'Raja Casablanca', 'Club Olympique de Medenine', 'Hammam-Sousse', 'KalaÃ¢ Sport', 'Japan', 'Al-Akhdar', 'Wales', 'FAR Rabat', 'Marumo Gallants', 'ASC Kara', 'Us Tataouine', 'Mamelodi Sundowns FC', 'Dinamo Zagreb', 'Brazil', 'USA', 'Australia', 'Esperance', 'Al Ahly', 'Algeria', 'Sao Tome And Principe', 'EO Sidi Bouzid', 'Costa Rica', 'Barcelona', 'RadÃ¨s', 'Ghana', 'Juventus', 'USM Alger', 'AS Vita Club', 'Club Africain', 'Spain', 'CA Bizertin', 'Eintracht Frankfurt', 'JS Kabylie', 'Coton Sport', 'Al-Merreikh', 'Slimane', 'JS Kairouanaise', 'Cameroon', 'ASEC Mimosas', 'Serbia', 'Madagascar', 'Saint-Eloi Lupopo', 'Nigeria', 'Djoliba AC', 'Ben Guerdane', 'Etoile Metlaoui', 'Viktoria Plzen', 'Sporting CP', 'CS Sfaxien', 'Cs Msaken', 'SS Sfaxien', 'Horoya AC', 'DR Congo', 'Senegal', 'Mali', 'Olympique de Beja', 'Morocco', 'SSC Napoli', 'Manchester City', 'Benin', 'Croatia', 'Botswana', 'Chelsea', 'Liverpool', 'Motema Pembe', 'Mozambique', 'Argentina', 'CR Belouizdad', 'Chebba', 'Petro Atletico', 'Rail Club De Kadiogo', 'Zarzis', 'Al-Nasr Club of Benghazi', 'Wydad Casablanca', 'AC Milan', 'Paris Saint Germain', 'Djelma', 'AS Bamako', 'Tottenham Hotspur', 'Mexico', 'Salzburg', 'Atletico Madrid', 'Saudi Arabia', 'El Makarem De Mahdia', 'Egs Gafsa', 'Real Madrid', 'Diables Noirs', 'AS Gabes', 'Al Ahli Tripoli', 'Tanzania', 'Kasserine', 'Bayer Leverkusen', 'Portugal', 'Belgium', 'Korba', 'Young Africans', 'Iran', 'Rwanda', 'Denmark', 'Gabon', 'Tshakhuma Madzivhadila FC', 'Sporting Gagnoa', 'Etoile du Sahel', 'Inter', 'ASKO de Kara', 'Namibia', 'Uruguay', 'Marseille', 'US Monastir', 'Vipers SC', 'Sierra Leone', 'Primeiro de Agosto']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competetions_ids = [\"362\",\"387\",\"227\",\"244\",\"223\",\"224\",\"427\",\"42\"]\n",
    "football_matches_rows = []\n",
    "teams = []\n",
    "for competetion_id in competetions_ids:\n",
    "    lll=requests.get(\"http://livescore-api.com/api-client/scores/history.json?from=2022-11-01&competition_id=\"+competetion_id+\"&key=ilfcBNNH7eyenwHH&secret=hfrVN6M8GP2S6sgpOwCpjp6rEFF2bnJt\")\n",
    "    ss = json.loads(lll.content)\n",
    "    for match in ss[\"data\"][\"match\"]:\n",
    "        city = 'TIS'\n",
    "        mdate = match[\"date\"]\n",
    "        mhour = match[\"scheduled\"]\n",
    "        mteamh = match[\"home_name\"]\n",
    "        mteama = match[\"away_name\"]\n",
    "        teams.append(mteama)\n",
    "        teams.append(mteamh)\n",
    "        if (mteamh in [\"Tunisia\",\"Brazil\",'Club Africain', 'CS Sfaxien', 'Manchester City','Real Madrid', 'Etoile du Sahel', 'Esperance']) or (mteama in [\"Tunisia\",\"Brazil\",'Club Africain', 'CS Sfaxien', 'Manchester City','Real Madrid', 'Etoile du Sahel', 'Esperance']):\n",
    "            if competetion_id in [\"223\",\"224\",\"427\",\"42\"]:\n",
    "                match_range = \"national\"\n",
    "            else:\n",
    "                match_range = \"international\"\n",
    "            if competetion_id in [\"42\"]:\n",
    "                match_type = \"league\"\n",
    "            elif competetion_id in [\"244\",\"223\",\"224\",\"427\"]:\n",
    "                match_type = \"cup\"\n",
    "            else:\n",
    "                match_type = \"eliminations\"\n",
    "        else:\n",
    "            continue\n",
    "        for i in range(-1,3,1):\n",
    "            if match_city ==\"ALL\":\n",
    "                for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                    football_matches_row = []\n",
    "                    football_matches_row.append(match_date)\n",
    "                    football_matches_row.append(str(int(mhour.split(\":\")[0])+i)+\":00\")\n",
    "                    football_matches_row.append(match_range)\n",
    "                    football_matches_row.append(match_type)\n",
    "                    football_matches_row.append(city)\n",
    "                    football_matches_rows.append(football_matches_row)\n",
    "            else:\n",
    "                city = match_city\n",
    "                football_matches_row = []\n",
    "                football_matches_row.append(match_date)\n",
    "                football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "                football_matches_row.append(match_range)\n",
    "                football_matches_row.append(match_type)\n",
    "                football_matches_row.append(city)\n",
    "                football_matches_rows.append(football_matches_row)\n",
    "football_histoical_data = pd.DataFrame(football_matches_rows)\n",
    "print(list(set(teams)))\n",
    "football_histoical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a652c",
   "metadata": {
    "id": "b34a652c",
    "outputId": "c7029e67-1cbe-4e72-eea3-1983f8306a1a"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m conti \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m conti\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter event, choose from [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for football match,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for other events]: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      7\u001b[0m         match_range\u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter match type, choose from [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnational\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternational\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# special_events_rows = []\n",
    "# football_matches_rows = []\n",
    "# conti = \"y\"\n",
    "# while conti==\"y\":\n",
    "#     event = input('Enter event, choose from [\"f\" for football match,\"e\" for other events]: ')\n",
    "#     if event == \"f\":\n",
    "#         match_range= input('Enter match type, choose from [\"national\",\"international\"]: ')\n",
    "#         match_type = input('Enter match type, choose from [\"friendly\",\"league\",\"cup\",\"eliminations\"]: ')\n",
    "#         match_date = input('Enter match date, use this format \"dd-mm-yyyy\" : ')\n",
    "#         match_start_hour = input('Enter match start hour, use this format \"hh:00\" : ')\n",
    "#         match_city = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "#         for i in range(-1,3,1):\n",
    "#             if match_city ==\"ALL\":\n",
    "#                 for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "#                     football_matches_row = []\n",
    "#                     football_matches_row.append(match_date)\n",
    "#                     football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "#                     football_matches_row.append(match_range)\n",
    "#                     football_matches_row.append(match_type)\n",
    "#                     football_matches_row.append(city)\n",
    "#                     football_matches_rows.append(football_matches_row)\n",
    "#             else:\n",
    "#                 city = match_city\n",
    "#                 football_matches_row = []\n",
    "#                 football_matches_row.append(match_date)\n",
    "#                 football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "#                 football_matches_row.append(match_range)\n",
    "#                 football_matches_row.append(match_type)\n",
    "#                 football_matches_row.append(city)\n",
    "#                 football_matches_rows.append(football_matches_row)\n",
    "#     else:\n",
    "#         special_events_row = []\n",
    "#         event_type = input('Enter event type, choose from [\"sudden_event\",\"expected_event\"]: ')\n",
    "#         event_category = input('Enter event category, choose from [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]: ')\n",
    "#         event_range = input('Enter event range, choose from [\"local\",\"regional\",\"national\",\"international\"]: ')\n",
    "#         event_impact = input('Enter event impact, choose from [\"small\",\"moderate\",\"big\"]: ')\n",
    "#         event_date = input('Enter event date, use this format \"dd-mm-yyyy\" : ')\n",
    "#         event_start_hour = input('Enter event start hour, use this format \"hh:00\" : ')\n",
    "#         event_duration = input('Enter event duration, use this format \"hh\" : ')\n",
    "#         event_city_code = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "#         special_events_row.append(event_type)\n",
    "#         special_events_row.append(event_category)\n",
    "#         special_events_row.append(event_range)\n",
    "#         special_events_row.append(event_impact)\n",
    "#         special_events_row.append(event_date)\n",
    "#         special_events_row.append(event_start_hour)\n",
    "#         special_events_row.append(event_duration)\n",
    "#         special_events_row.append(event_city_code)\n",
    "#         special_events_rows.append(special_events_row)\n",
    "#     conti = input('add another event ? y/n: ')\n",
    "\n",
    "# special_events_final_rows = []\n",
    "# for cells in special_events_rows:\n",
    "#     duration = int(cells[6].split(\":\")[0])\n",
    "#     for i in range(duration):\n",
    "#         if cells[7]==\"ALL\":\n",
    "#             for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "#                 ser= []\n",
    "#                 hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "#                 ser.append(cells[4])\n",
    "#                 ser.append(hour)\n",
    "#                 ser.append(city)\n",
    "#                 ser.append(cells[0])\n",
    "#                 ser.append(cells[1])\n",
    "#                 ser.append(cells[2])\n",
    "#                 ser.append(cells[3])\n",
    "#                 special_events_final_rows.append(ser)\n",
    "#         else:\n",
    "#             ser= []\n",
    "#             city = cells[7]\n",
    "#             hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "#             ser.append(cells[4])\n",
    "#             ser.append(hour)\n",
    "#             ser.append(city)\n",
    "#             ser.append(cells[0])\n",
    "#             ser.append(cells[1])\n",
    "#             ser.append(cells[2])\n",
    "#             ser.append(cells[3])\n",
    "#             special_events_final_rows.append(ser)\n",
    "\n",
    "# special_events_df = pd.DataFrame(special_events_final_rows)\n",
    "# special_events_df.rename(columns={0:\"date_data\",1:\"hour_data\",2:\"city_code\",3:\"event_type\",4:\"event_category\",5:\"event_range\",6:\"event_impact\"},inplace=True)\n",
    "# football_matches_df = pd.DataFrame(football_matches_rows)\n",
    "# football_matches_df[\"match_range\"] = football_matches_df[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "# football_matches_df[\"match_type\"] = football_matches_df[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "# football_matches_df.sort_values([\"date_data\",\"city_code\",\"hour_data\",\"match_range\",\"match_type\"], inplace=True, ascending=[True,True,True,False,False])\n",
    "# football_matches_df.drop_duplicates(subset = [\"date_data\",\"hour_data\",\"city_code\"], keep = \"first\", inplace=True)\n",
    "# football_matches_df.rename(columns={0:\"date_data\",1:\"hour_data\",3:\"match_type\",2:\"match_range\",4:\"city_code\"},inplace=True)\n",
    "# final_df = pd.merge(football_matches_df,special_events_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"outer\")\n",
    "# final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "# final_df[\"hour_data\"] = final_df[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "# display(final_df)\n",
    "# final_df.to_csv(\"special_events_historical.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
