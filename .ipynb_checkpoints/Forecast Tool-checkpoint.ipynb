{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a710f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import trino\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912d45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glovo\\AppData\\Local\\Temp\\ipykernel_19664\\2019379743.py:87: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  expected_couriers = pd.read_sql_query(expected_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the following URL in browser for the external authentication:\n",
      "https://starburst.g8s-data-platform-prod.glovoint.com/oauth2/token/initiate/3c04b9a1778cf316ddb9a62d754f418c702a26918bf7ddda2df325c11e5180a6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Glovo\\AppData\\Local\\Temp\\ipykernel_19664\\2019379743.py:88: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  active_couriers = pd.read_sql_query(active_query, conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_data</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>city_code</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>active_couriers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>22:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>Tue</td>\n",
       "      <td>22:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25429</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>01:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25430</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>01:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25431</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>00:00</td>\n",
       "      <td>SFX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25432</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>00:00</td>\n",
       "      <td>SOU</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>Wed</td>\n",
       "      <td>00:00</td>\n",
       "      <td>TIS</td>\n",
       "      <td>114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25434 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_data weekday hour_data city_code  expected_couriers  \\\n",
       "0     2022-11-01     Tue     23:00       SFX                0.0   \n",
       "1     2022-11-01     Tue     23:00       SOU                0.0   \n",
       "2     2022-11-01     Tue     23:00       TIS               26.0   \n",
       "3     2022-11-01     Tue     22:00       SFX                2.0   \n",
       "4     2022-11-01     Tue     22:00       SOU                4.0   \n",
       "...          ...     ...       ...       ...                ...   \n",
       "25429 2024-02-14     Wed     01:00       SOU                0.0   \n",
       "25430 2024-02-14     Wed     01:00       TIS               51.0   \n",
       "25431 2024-02-14     Wed     00:00       SFX                4.0   \n",
       "25432 2024-02-14     Wed     00:00       SOU                8.0   \n",
       "25433 2024-02-14     Wed     00:00       TIS              114.0   \n",
       "\n",
       "       active_couriers  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                 19.0  \n",
       "3                  3.0  \n",
       "4                  2.0  \n",
       "...                ...  \n",
       "25429              NaN  \n",
       "25430              NaN  \n",
       "25431              NaN  \n",
       "25432              NaN  \n",
       "25433              NaN  \n",
       "\n",
       "[25434 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### Get the time parameters ##########################\n",
    "\n",
    "today = date.today()\n",
    "yesterday = today - timedelta(days = 1)\n",
    "tomorrow = today + timedelta(days = 1)\n",
    "city = \"TIS\"\n",
    "########################### Get the city parameters ###########################\n",
    "\n",
    "# Get the city urls\n",
    "if city == \"TIS\":\n",
    "    url_historical = \"https://archive-api.open-meteo.com/v1/archive?latitude=36.7498325&longitude=10.2676506&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred = \"https://api.open-meteo.com/v1/forecast?latitude=36.7498325&longitude=10.2676506&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "elif city == \"SOU\":\n",
    "    url_historical = \"https://archive-api.open-meteo.com/v1/archive?latitude=35.8059273&longitude=10.6488785&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred = \"https://api.open-meteo.com/v1/forecast?latitude=35.8059273&longitude=10.6488785&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "elif city == \"SFX\":\n",
    "    url_historical = \"https://archive-api.open-meteo.com/v1/archive?latitude=35.0177587&longitude=10.5943665&start_date=2022-11-01&end_date=\"+str(yesterday)+\"&hourly=temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_100m,winddirection_100m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon\"\n",
    "    url_pred = \"https://api.open-meteo.com/v1/forecast?latitude=35.0177587&longitude=10.5943665&hourly=precipitation_probability,temperature_2m,relativehumidity_2m,apparent_temperature,precipitation,rain,cloudcover,windspeed_80m,winddirection_80m,is_day&daily=sunrise,sunset,precipitation_sum,rain_sum&timezone=Europe%2FLondon&start_date=\"+str(today)+\"&end_date=\"+str(tomorrow)\n",
    "    \n",
    "# Get the city model\n",
    "if city == \"TIS\":\n",
    "    model_pkl_file = \"model_tis.pkl\"\n",
    "elif city == \"SOU\":\n",
    "    model_pkl_file = \"model_sou.pkl\"\n",
    "elif city == \"SFX\":\n",
    "    model_pkl_file = \"model_sfx.pkl\"\n",
    "\n",
    "########################### set up the connection ###########################\n",
    "\n",
    "# you need not change these\n",
    "HOST = 'starburst.g8s-data-platform-prod.glovoint.com'\n",
    "PORT = 443\n",
    "\n",
    "# prepare your query, this will\n",
    "# list all columns in the Customer Behaviour Data Product\n",
    "expected_query = '''\n",
    "SELECT\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at ,'%Y-%m-%d') AS \"date_data\",\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%a') AS weekday,\n",
    "    DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%H:%i') AS \"hour_data\",\n",
    "    cities_v2.city_code AS \"city_code\",\n",
    "    SUM(capacity_changes_slot_level.couriers_expected) AS \"expected_couriers\"\n",
    "FROM delta.courier_forecasting_odp.capacity_changes_slot_level  AS capacity_changes_slot_level\n",
    "LEFT JOIN delta.central_geography_odp.cities_v2  AS cities_v2 ON capacity_changes_slot_level.city_code = cities_v2.city_code\n",
    "WHERE \n",
    " DATE(capacity_changes_slot_level.scheduling_slot_started_local_at) >= DATE('2022-11-01')\n",
    "AND DATE(capacity_changes_slot_level.scheduling_slot_started_local_at) < DATE(DATE_ADD('day',2,CURRENT_DATE))\n",
    "AND cities_v2.country_code = 'TN'\n",
    "AND DATE_FORMAT(capacity_changes_slot_level.scheduling_slot_started_local_at, '%H:%i') NOT IN ('03:00','04:00','05:00','06:00','07:00','08:00')\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY 1,2,3 DESC,4\n",
    "'''\n",
    "active_query = '''\n",
    "SELECT\n",
    "    DATE(ss.scheduling_slot_started_local_at) AS date_data,\n",
    "    DATE_FORMAT(ss.scheduling_slot_started_local_at, '%a') AS weekday,\n",
    "    DATE_FORMAT(ss.scheduling_slot_started_local_at, '%H:%i') AS hour_data,\n",
    "    kpi_orders.order_city_code AS city_code,\n",
    "    -- active couriers\n",
    "    COUNT(DISTINCT CASE WHEN kpi_orders.order_final_status='DeliveredStatus' THEN kpi_orders.courier_id ELSE NULL END) AS active_couriers\n",
    "\n",
    "FROM delta.central_order_descriptors_odp.order_descriptors_v2 kpi_orders\n",
    "    LEFT JOIN delta.courier_dispatching_engine_odp.order_slot_zone_master slot_zone ON slot_zone.order_id = kpi_orders.order_id\n",
    "    LEFT JOIN delta.courier_logistics_scheduling_odp.scheduling_slots ss ON ss.scheduling_slot_id = slot_zone.scheduling_slot_id\n",
    "    LEFT JOIN delta.courier_order_flow_odp.delivery_times_logistics_order_level_attributes dt_info ON dt_info.order_id = kpi_orders.order_id\n",
    "    LEFT JOIN delta.courier_core_cpo_odp.order_level_v2 cpo ON cpo.order_id=kpi_orders.order_id\n",
    "WHERE slot_zone.order_city_code IN ('TIS','SFX','SOU')\n",
    "    AND DATE(ss.scheduling_slot_started_local_at) >= DATE('2022-11-01')\n",
    "    AND DATE(ss.scheduling_slot_started_local_at) < CURRENT_DATE\n",
    "    AND kpi_orders.order_handling_strategy='GEN2'\n",
    "    AND DATE_FORMAT(ss.scheduling_slot_started_local_at, '%H:%i') NOT IN ('03:00','04:00','05:00','06:00','07:00','08:00')\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY 1,2,3 DESC,4\n",
    "'''\n",
    "\n",
    "conn_details = {\n",
    "    'host': HOST,\n",
    "    'port': PORT,\n",
    "    'http_scheme': 'https',\n",
    "    'auth': trino.auth.OAuth2Authentication()\n",
    "}\n",
    "\n",
    "\n",
    "# To export result to pandas\n",
    "with trino.dbapi.connect(**conn_details) as conn:\n",
    "    \n",
    "    expected_couriers = pd.read_sql_query(expected_query, conn)\n",
    "    active_couriers = pd.read_sql_query(active_query, conn) \n",
    "\n",
    "########################### Process data to get training data and prediction data ###########################\n",
    "expected_couriers[\"date_data\"] = pd.to_datetime(expected_couriers[\"date_data\"])\n",
    "active_couriers[\"date_data\"] = pd.to_datetime(active_couriers[\"date_data\"])\n",
    "data = pd.merge(expected_couriers,active_couriers,on=[\"date_data\",'hour_data',\"weekday\",'city_code'],how=\"outer\")\n",
    "display(data)\n",
    "data_train = data[data[\"active_couriers\"].isna()==False].copy()\n",
    "data_predict = data[(data[\"active_couriers\"].isna()) & (pd.to_datetime(data[\"date_data\"]).dt.date>=today)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433a1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding functions to ensure consistency across training data and prediction data\n",
    "\n",
    "def extract_action(row):\n",
    "    \n",
    "\n",
    "def adjust_active_coureirs(row):\n",
    "    if row[\"active_couriers\"] > row[\"expected_couriers\"]:\n",
    "        return row[\"expected_couriers\"]\n",
    "    else:\n",
    "        return row[\"active_couriers\"]\n",
    "\n",
    "def encode_weekday(weekday): \n",
    "    weekdays = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    if weekday in weekdays:\n",
    "        return weekdays.index(weekday)\n",
    "    else:\n",
    "        assert(\"Verify that weekday is in the correct format ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\")\n",
    "        \n",
    "def decode_week_day(weekday):\n",
    "    weekdays = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "    return weekdays[weekday]\n",
    "        \n",
    "def encode_match_range(match_range):\n",
    "    match_ranges = [\"national\",\"international\"]\n",
    "    if match_range in match_ranges:\n",
    "        return match_ranges.index(match_range)+1\n",
    "    else:\n",
    "        assert('Verify that match_range is in the correct format [\"national\",\"international\"]')\n",
    "        \n",
    "def encode_match_type(match_type):\n",
    "    match_types = [\"league\",\"cup\",\"final\",\"friendly\"]\n",
    "    if match_type in match_types:\n",
    "        return match_types.index(match_type)+1\n",
    "    else:\n",
    "        assert('Verify that match_type is in the correct format [\"league\",\"cup\",\"final\",\"friendly\"]')\n",
    "        \n",
    "def encode_event_type(event_type):\n",
    "    event_types = [\"sudden_event\",\"expected_event\"]\n",
    "    if event_type in event_types:\n",
    "        return event_types.index(event_type)+1\n",
    "    else:\n",
    "        assert('Verify that event_type is in the correct format [\"sudden_event\",\"expected_event\"]')\n",
    "\n",
    "\n",
    "def encode_event_category(event_category):\n",
    "    event_categorys = [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]\n",
    "    if event_category in event_categorys:\n",
    "        return event_categorys.index(event_category)+1\n",
    "    else:\n",
    "        assert('Verify that event_category is in the correct format [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]')\n",
    "        \n",
    "def encode_event_range(event_range):\n",
    "    event_ranges = [\"local\",\"regional\",\"national\",\"international\"]\n",
    "    if event_range in event_ranges:\n",
    "        return event_ranges.index(event_range)+1\n",
    "    else:\n",
    "        assert('Verify that event_range is in the correct format [\"local\",\"regional\",\"national\",\"international\"]')\n",
    "        \n",
    "def encode_event_impact(event_impact):\n",
    "    event_impacts = [\"national\",\"international\"]\n",
    "    if event_impact in event_impacts:\n",
    "        return event_impacts.index(event_impact)+1\n",
    "    else:\n",
    "        assert('Verify that event_impact is in the correct format [\"small\",\"moderate\",\"big\"]')\n",
    "        \n",
    "def encode_hour_data(hour_data):\n",
    "    hours = [\"09:00\",\"10:00\",\"11:00\",\"12:00\",\"13:00\",\"14:00\",\"15:00\",\"16:00\",\"17:00\",\"18:00\",\"19:00\",\"20:00\",\"21:00\",\"22:00\",\"23:00\",\"00:00\",\"01:00\"]\n",
    "    if hour_data in hours:\n",
    "        return hours.index(hour_data)+1\n",
    "    else:\n",
    "        assert('Verify that hour_data is in the correct format hh:mm ')\n",
    "        \n",
    "def decode_hour_data(hour_data):   \n",
    "    hours = [\"09:00\",\"10:00\",\"11:00\",\"12:00\",\"13:00\",\"14:00\",\"15:00\",\"16:00\",\"17:00\",\"18:00\",\"19:00\",\"20:00\",\"21:00\",\"22:00\",\"23:00\",\"00:00\",\"01:00\"]\n",
    "    return hours[hour_data-1]\n",
    "    \n",
    "def get_special_events():\n",
    "    special_events_rows = []\n",
    "    football_matches_rows = []\n",
    "    conti = input('Do you want to add an event ? y/n: ')\n",
    "    if conti == \"y\":\n",
    "        while conti==\"y\":\n",
    "            event = input('Enter event, choose from [\"f\" for football match,\"e\" for other events]: ')\n",
    "            if event == \"f\":\n",
    "                match_range= input('Enter match type, choose from [\"national\",\"international\"]: ')\n",
    "                match_type = input('Enter match type, choose from [\"league\",\"cup\",\"final\",\"friendly\"]: ')\n",
    "                match_date = input('Enter match date, use this format \"dd-mm-yyyy\" : ')\n",
    "                match_start_hour = input('Enter match start hour, use this format \"hh:00\" : ')\n",
    "                match_city = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "                for i in range(-1,3,1):\n",
    "                    if match_city ==\"ALL\":\n",
    "                        for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                            football_matches_row = []\n",
    "                            football_matches_row.append(match_date)\n",
    "                            football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "                            football_matches_row.append(match_range)\n",
    "                            football_matches_row.append(match_type)\n",
    "                            football_matches_row.append(city)\n",
    "                            football_matches_rows.append(football_matches_row)\n",
    "                    else:\n",
    "                        city = match_city\n",
    "                        football_matches_row = []\n",
    "                        football_matches_row.append(match_date)\n",
    "                        football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "                        football_matches_row.append(match_range)\n",
    "                        football_matches_row.append(match_type)\n",
    "                        football_matches_row.append(city)\n",
    "                        football_matches_rows.append(football_matches_row)\n",
    "            else:\n",
    "                special_events_row = []\n",
    "                event_type = input('Enter event type, choose from [\"sudden_event\",\"expected_event\"]: ')\n",
    "                event_category = input('Enter event category, choose from [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]: ')\n",
    "                event_range = input('Enter event range, choose from [\"local\",\"regional\",\"national\",\"international\"]: ')\n",
    "                event_impact = input('Enter event impact, choose from [\"small\",\"moderate\",\"big\"]: ')\n",
    "                event_date = input('Enter event date, use this format \"dd-mm-yyyy\" : ')\n",
    "                event_start_hour = input('Enter event start hour, use this format \"hh:00\" : ')\n",
    "                event_duration = input('Enter event duration, use this format \"hh\" : ')\n",
    "                event_city_code = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "                special_events_row.append(event_type)\n",
    "                special_events_row.append(event_category)\n",
    "                special_events_row.append(event_range)\n",
    "                special_events_row.append(event_impact)\n",
    "                special_events_row.append(event_date)\n",
    "                special_events_row.append(event_start_hour)\n",
    "                special_events_row.append(event_duration)\n",
    "                special_events_row.append(event_city_code)\n",
    "                special_events_rows.append(special_events_row)\n",
    "            conti = input('add another event ? y/n: ')\n",
    "\n",
    "        special_events_final_rows = []\n",
    "        for cells in special_events_rows:\n",
    "            duration = int(cells[6].split(\":\")[0])\n",
    "            for i in range(duration):\n",
    "                if cells[7]==\"ALL\":\n",
    "                    for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                        ser= []\n",
    "                        hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "                        ser.append(cells[4])\n",
    "                        ser.append(hour)\n",
    "                        ser.append(city)\n",
    "                        ser.append(cells[0])\n",
    "                        ser.append(cells[1])\n",
    "                        ser.append(cells[2])\n",
    "                        ser.append(cells[3])\n",
    "                        special_events_final_rows.append(ser)\n",
    "                else:\n",
    "                    ser= []\n",
    "                    city = cells[7]\n",
    "                    hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "                    ser.append(cells[4])\n",
    "                    ser.append(hour)\n",
    "                    ser.append(city)\n",
    "                    ser.append(cells[0])\n",
    "                    ser.append(cells[1])\n",
    "                    ser.append(cells[2])\n",
    "                    ser.append(cells[3])\n",
    "                    special_events_final_rows.append(ser)\n",
    "\n",
    "        special_events_df = pd.DataFrame(special_events_final_rows)\n",
    "        special_events_df.rename(columns={0:\"date_data\",1:\"hour_data\",2:\"city_code\",3:\"event_type\",4:\"event_category\",5:\"event_range\",6:\"event_impact\"},inplace=True)\n",
    "        football_matches_df = pd.DataFrame(football_matches_rows)\n",
    "        football_matches_df[\"match_range\"] = football_matches_df[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "        football_matches_df[\"match_type\"] = football_matches_df[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "        football_matches_df.sort_values([\"date_data\",\"city_code\",\"hour_data\",\"match_range\",\"match_type\"], inplace=True, ascending=[True,True,True,False,False]) \n",
    "        football_matches_df.drop_duplicates(subset = [\"date_data\",\"hour_data\",\"city_code\"], keep = \"first\", inplace=True)\n",
    "        football_matches_df.rename(columns={0:\"date_data\",1:\"hour_data\",3:\"match_type\",2:\"match_range\",4:\"city_code\"},inplace=True)\n",
    "        final_df = pd.merge(football_matches_df,special_events_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"outer\")\n",
    "        final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "        final_df[\"hour_data\"] = final_df[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "        return final_df\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"date_data\",\"hour_data\",\"city_code\",\"match_range\",\"match_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e125f05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relativehumidity_2m</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>rain</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>weekday</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>month</th>\n",
       "      <th>match_range</th>\n",
       "      <th>match_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>53.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>42.6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>297.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>50.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>280.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>61.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>77.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>86.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6218 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      relativehumidity_2m  apparent_temperature  rain  cloudcover  wind_speed  \\\n",
       "0                    69.0                  16.5   0.0         1.0        18.8   \n",
       "1                    79.0                  17.8   0.0         0.0        18.0   \n",
       "2                    79.0                  17.8   0.0         0.0        18.0   \n",
       "3                    79.0                  17.8   0.0         0.0        18.0   \n",
       "4                    79.0                  17.8   0.0         0.0        18.0   \n",
       "...                   ...                   ...   ...         ...         ...   \n",
       "6213                 53.0                   9.3   0.0        58.0        42.6   \n",
       "6214                 50.0                  10.2   0.0        39.0        39.4   \n",
       "6215                 61.0                   8.8   0.0        28.0        36.8   \n",
       "6216                 77.0                   8.5   0.0        13.0        29.4   \n",
       "6217                 86.0                   8.9   0.0         3.0        25.3   \n",
       "\n",
       "      hour_data  weekday  expected_couriers  month  match_range  match_type  \n",
       "0            15        1               26.0     11            0           0  \n",
       "1            14        1               46.0     11            2           3  \n",
       "2            14        1               46.0     11            2           3  \n",
       "3            14        1               46.0     11            2           3  \n",
       "4            14        1               46.0     11            2           3  \n",
       "...         ...      ...                ...    ...          ...         ...  \n",
       "6213          6        6              297.0      2            0           0  \n",
       "6214          5        6              280.0      2            0           0  \n",
       "6215          1        6               25.0      2            0           0  \n",
       "6216         17        6               81.0      2            0           0  \n",
       "6217         16        6              163.0      2            0           0  \n",
       "\n",
       "[6218 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree R-squared score (test): 0.932\n",
      "tree Mean squared error: 261.808\n",
      "tree Mean absolute error: 9.880\n"
     ]
    }
   ],
   "source": [
    "######################################## Training Process ########################################\n",
    "\n",
    "# Get the data train for the city\n",
    "city_data_train = data_train[data_train[\"city_code\"]==city].copy()\n",
    "\n",
    "########################### Process the data to prepare it for modeling ###########################\n",
    "\n",
    "#### Prepare Weather Data\n",
    "\n",
    "# Load and process weather data for the city\n",
    "\n",
    "historical_response = requests.get(url_historical)\n",
    "data_historical = json.loads(historical_response.content)\n",
    "weather_data = pd.DataFrame(data_historical[\"hourly\"])\n",
    "weather_data[\"date_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[0])\n",
    "weather_data[\"hour_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[1])\n",
    "weather_data[\"city_code\"] = city\n",
    "weather_data[\"hour_data\"] = weather_data[\"hour_data\"].apply(lambda x: x if x not in [\"02:00\",\"03:00\",\"04:00\",\"05:00\",\"06:00\",\"07:00\",\"08:00\"] else None)\n",
    "weather_data[\"date_data\"] = pd.to_datetime(weather_data[\"date_data\"])\n",
    "weather_data = weather_data.dropna()\n",
    "# Drop rows from weather_data with dates higher than those in data_train\n",
    "weather_data = weather_data[(pd.to_datetime(weather_data[\"date_data\"])<=pd.to_datetime(data_train[\"date_data\"].max()))].reset_index(drop=True)\n",
    "weather_data = weather_data.sort_values(['date_data', 'hour_data','city_code'],ascending = [True, False, True]).reset_index(drop=True)\n",
    "# Merge the dfs and keep processing \n",
    "city_data_train = pd.merge(weather_data,data_train,on=['date_data', 'hour_data','city_code'])\n",
    "city_data_train[\"month\"] = city_data_train[\"date_data\"].apply(lambda x:int(str(x).split(\"-\")[1]))\n",
    "city_data_train[\"weekday\"] = city_data_train[\"weekday\"].apply(encode_weekday)\n",
    "# drop unnacessary rows and columns\n",
    "city_data_train.rename(columns={\"winddirection_100m\":\"wind_direction\",\"windspeed_100m\":\"wind_speed\"},inplace=True)\n",
    "city_data_train.dropna()\n",
    "city_data_train = city_data_train[city_data_train[\"active_couriers\"] >1]\n",
    "city_data_train = city_data_train[city_data_train[\"expected_couriers\"]>=city_data_train[\"active_couriers\"]]\n",
    "\n",
    "#### Prepare special events data\n",
    "\n",
    "final_df = pd.read_csv(\"special_events_historical.csv\")\n",
    "final_df = final_df.iloc[: , 1:]\n",
    "final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "city_data_train = city_data_train.merge(final_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"left\")\n",
    "city_data_train[\"hour_data\"] = city_data_train[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "city_data_train[\"match_range\"] = city_data_train[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "city_data_train[\"match_type\"] = city_data_train[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "# city_data_train[\"event_type\"] = city_data_train[\"event_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_type(x))\n",
    "# city_data_train[\"event_category\"] = city_data_train[\"event_category\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_category(x))\n",
    "# city_data_train[\"event_range\"] = city_data_train[\"event_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_range(x))\n",
    "# city_data_train[\"event_impact\"] = city_data_train[\"event_impact\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_impact(x))\n",
    "\n",
    "########################### Train Model ###########################\n",
    "\n",
    "y = city_data_train[\"active_couriers\"]\n",
    "X = city_data_train.drop([\"temperature_2m\",\"active_couriers\",\"precipitation\",\"time\",\"date_data\",\"is_day\",\"city_code\",\"wind_direction\"],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20)\n",
    "display(X)\n",
    "regressor = DecisionTreeRegressor(criterion=\"poisson\",splitter = \"best\",max_depth = 10).fit(X_train, np.log(y_train))\n",
    "regressor_pred = np.exp(regressor.predict(X_test))\n",
    "\n",
    "########################### Print results ###########################\n",
    "\n",
    "print('tree R-squared score (test): {:.3f}'.format(regressor.score(X_test, np.log(y_test))))\n",
    "print('tree Mean squared error: {:.3f}'.format(mean_squared_error(y_test, regressor_pred)))\n",
    "print('tree Mean absolute error: {:.3f}'.format(mean_absolute_error(y_test, regressor_pred)))\n",
    "\n",
    "########################### Save the model ###########################\n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:\n",
    "    pickle.dump(regressor, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79726487",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to add an eventn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_data</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>weekday</th>\n",
       "      <th>expected_couriers</th>\n",
       "      <th>active_couriers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>23:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>168.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>242.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>21:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>349.0</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>422.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>19:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>407.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>328.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>221.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>218.0</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>205.0</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>261.0</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>398.0</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>449.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>11:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>175.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>10:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>09:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>01:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Tue</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>23:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>170.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>22:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>254.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>21:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>351.0</td>\n",
       "      <td>294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>445.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>19:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>467.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>359.0</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>239.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>16:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>15:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>232.0</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>14:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>306.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>13:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>447.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>12:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>449.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>11:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>168.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>10:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>09:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>01:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>51.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-02-14</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Wed</td>\n",
       "      <td>114.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_data hour_data weekday  expected_couriers  active_couriers\n",
       "0  2024-02-13     23:00     Tue              168.0            137.0\n",
       "1  2024-02-13     22:00     Tue              242.0            217.0\n",
       "2  2024-02-13     21:00     Tue              349.0            294.0\n",
       "3  2024-02-13     20:00     Tue              422.0            397.0\n",
       "4  2024-02-13     19:00     Tue              407.0            397.0\n",
       "5  2024-02-13     18:00     Tue              328.0            315.0\n",
       "6  2024-02-13     17:00     Tue              221.0            185.0\n",
       "7  2024-02-13     16:00     Tue              218.0            201.0\n",
       "8  2024-02-13     15:00     Tue              205.0            201.0\n",
       "9  2024-02-13     14:00     Tue              261.0            245.0\n",
       "10 2024-02-13     13:00     Tue              398.0            335.0\n",
       "11 2024-02-13     12:00     Tue              449.0            349.0\n",
       "12 2024-02-13     11:00     Tue              175.0            183.0\n",
       "13 2024-02-13     10:00     Tue               41.0             33.0\n",
       "14 2024-02-13     09:00     Tue               23.0             21.0\n",
       "15 2024-02-13     01:00     Tue               53.0             20.0\n",
       "16 2024-02-13     00:00     Tue              116.0             83.0\n",
       "17 2024-02-14     23:00     Wed              170.0            150.0\n",
       "18 2024-02-14     22:00     Wed              254.0            217.0\n",
       "19 2024-02-14     21:00     Wed              351.0            294.0\n",
       "20 2024-02-14     20:00     Wed              445.0            397.0\n",
       "21 2024-02-14     19:00     Wed              467.0            397.0\n",
       "22 2024-02-14     18:00     Wed              359.0            355.0\n",
       "23 2024-02-14     17:00     Wed              239.0            217.0\n",
       "24 2024-02-14     16:00     Wed              210.0            210.0\n",
       "25 2024-02-14     15:00     Wed              232.0            205.0\n",
       "26 2024-02-14     14:00     Wed              306.0            257.0\n",
       "27 2024-02-14     13:00     Wed              447.0            349.0\n",
       "28 2024-02-14     12:00     Wed              449.0            349.0\n",
       "29 2024-02-14     11:00     Wed              168.0            183.0\n",
       "30 2024-02-14     10:00     Wed               35.0             36.0\n",
       "31 2024-02-14     09:00     Wed               17.0             15.0\n",
       "32 2024-02-14     01:00     Wed               51.0             25.0\n",
       "33 2024-02-14     00:00     Wed              114.0             83.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################## Prediction Process ########################################\n",
    "\n",
    "# Get the data pedict for the city\n",
    "city_data_predict = data_predict[data_predict[\"city_code\"]==city].copy()\n",
    "\n",
    "########################### Process the data to prepare it for modeling ###########################\n",
    "\n",
    "#### Prepare Weather Data\n",
    "\n",
    "# Load weather data for the city\n",
    "pred_response = requests.get(url_pred)\n",
    "data_pred = json.loads(pred_response.content)\n",
    "weather_data = pd.DataFrame(data_pred[\"hourly\"])\n",
    "weather_data[\"date_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[0])\n",
    "weather_data[\"hour_data\"] = weather_data[\"time\"].apply(lambda x:x.split(\"T\")[1])\n",
    "weather_data[\"city_code\"] = city\n",
    "weather_data[\"hour_data\"] = weather_data[\"hour_data\"].apply(lambda x: x if x not in [\"02:00\",\"03:00\",\"04:00\",\"05:00\",\"06:00\",\"07:00\",\"08:00\"] else None)\n",
    "weather_data[\"date_data\"] = pd.to_datetime(weather_data[\"date_data\"])\n",
    "weather_data = weather_data.dropna()\n",
    "# Drop rows from weather_data with dates lower than those in city_data_predict\n",
    "weather_data = weather_data[(pd.to_datetime(weather_data[\"date_data\"])<=pd.to_datetime(city_data_predict[\"date_data\"].max()))].reset_index(drop=True)\n",
    "weather_data = weather_data.sort_values(['date_data', 'hour_data','city_code'],ascending = [True, False, True]).reset_index(drop=True)\n",
    "# Merge the dfs and keep processing \n",
    "city_data_predict = pd.merge(weather_data,city_data_predict,on=['date_data', 'hour_data','city_code'])\n",
    "city_data_predict[\"month\"] = city_data_predict[\"date_data\"].apply(lambda x:int(str(x).split(\"-\")[1]))\n",
    "city_data_predict[\"weekday\"] = city_data_predict[\"weekday\"].apply(encode_weekday)\n",
    "# drop unnacessary rows and columns\n",
    "city_data_predict.rename(columns={\"winddirection_80m\":\"wind_direction\",\"windspeed_80m\":\"wind_speed\"},inplace=True)\n",
    "city_data_predict.drop([\"precipitation\",\"time\"],inplace=True,axis=1)\n",
    "\n",
    "#### Prepare special events data\n",
    "\n",
    "final_df = get_special_events()\n",
    "final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "city_data_predict = city_data_predict.merge(final_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"left\")\n",
    "city_data_predict[\"match_range\"] = city_data_predict[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "city_data_predict[\"match_type\"] = city_data_predict[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "city_data_predict[\"hour_data\"] = city_data_predict[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "# city_data_predict[\"event_type\"] = city_data_predict[\"event_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_type(x))\n",
    "# city_data_predict[\"event_category\"] = city_data_predict[\"event_category\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_category(x))\n",
    "# city_data_predict[\"event_range\"] = city_data_predict[\"event_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_range(x))\n",
    "# city_data_predict[\"event_impact\"] = city_data_predict[\"event_impact\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_event_impact(x))\n",
    "\n",
    "################## make predictions and display results ####################\n",
    "\n",
    "# Load Model\n",
    "with open(model_pkl_file, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Make predictions\n",
    "data_test = city_data_predict.drop([\"precipitation_probability\",\"temperature_2m\",\"active_couriers\",\"is_day\",\"city_code\",\"wind_direction\"],axis=1)\n",
    "preds = np.exp(model.predict(data_test.drop(\"date_data\",axis=1)))\n",
    "data_test[\"active_couriers\"] = np.round(preds,0)\n",
    "data_test[\"active_couriers\"] = data_test.apply(adjust_active_coureirs,axis = 1)\n",
    "data_test[\"potentiel_action\"] = data_test.apply(extract_action,axis = 1)\n",
    "data_test[\"hour_data\"] = data_test[\"hour_data\"].apply(decode_hour_data)\n",
    "data_test[\"weekday\"] = data_test[\"weekday\"].apply(decode_week_day)\n",
    "display(data_test[[\"date_data\",\"hour_data\",\"weekday\",\"expected_couriers\",\"active_couriers\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b34a652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_events_rows = []\n",
    "# football_matches_rows = []\n",
    "# conti = \"y\"\n",
    "# while conti==\"y\":\n",
    "#     event = input('Enter event, choose from [\"f\" for football match,\"e\" for other events]: ')\n",
    "#     if event == \"f\":\n",
    "#         match_range= input('Enter match type, choose from [\"national\",\"international\"]: ')\n",
    "#         match_type = input('Enter match type, choose from [\"friendly\",\"league\",\"cup\",\"final\"]: ')\n",
    "#         match_date = input('Enter match date, use this format \"dd-mm-yyyy\" : ')\n",
    "#         match_start_hour = input('Enter match start hour, use this format \"hh:00\" : ')\n",
    "#         match_city = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "#         for i in range(-1,3,1):\n",
    "#             if match_city ==\"ALL\":\n",
    "#                 for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "#                     football_matches_row = []\n",
    "#                     football_matches_row.append(match_date)\n",
    "#                     football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "#                     football_matches_row.append(match_range)\n",
    "#                     football_matches_row.append(match_type)\n",
    "#                     football_matches_row.append(city)\n",
    "#                     football_matches_rows.append(football_matches_row)\n",
    "#             else:\n",
    "#                 city = match_city\n",
    "#                 football_matches_row = []\n",
    "#                 football_matches_row.append(match_date)\n",
    "#                 football_matches_row.append(str(int(match_start_hour.split(\":\")[0])+i)+\":00\")\n",
    "#                 football_matches_row.append(match_range)\n",
    "#                 football_matches_row.append(match_type)\n",
    "#                 football_matches_row.append(city)\n",
    "#                 football_matches_rows.append(football_matches_row)\n",
    "#     else:\n",
    "#         special_events_row = []\n",
    "#         event_type = input('Enter event type, choose from [\"sudden_event\",\"expected_event\"]: ')\n",
    "#         event_category = input('Enter event category, choose from [\"sports_event\",\"political_event\",\"holiday\",\"social_event\",\"festival\"]: ')\n",
    "#         event_range = input('Enter event range, choose from [\"local\",\"regional\",\"national\",\"international\"]: ')\n",
    "#         event_impact = input('Enter event impact, choose from [\"small\",\"moderate\",\"big\"]: ')\n",
    "#         event_date = input('Enter event date, use this format \"dd-mm-yyyy\" : ')\n",
    "#         event_start_hour = input('Enter event start hour, use this format \"hh:00\" : ')\n",
    "#         event_duration = input('Enter event duration, use this format \"hh\" : ')\n",
    "#         event_city_code = input('Enter event city, choose from [\"SOU\",\"TIS\",\"SFX\",\"ALL\"]: ')\n",
    "#         special_events_row.append(event_type)\n",
    "#         special_events_row.append(event_category)\n",
    "#         special_events_row.append(event_range)\n",
    "#         special_events_row.append(event_impact)\n",
    "#         special_events_row.append(event_date)\n",
    "#         special_events_row.append(event_start_hour)\n",
    "#         special_events_row.append(event_duration)\n",
    "#         special_events_row.append(event_city_code)\n",
    "#         special_events_rows.append(special_events_row)\n",
    "#     conti = input('add another event ? y/n: ')\n",
    "    \n",
    "# special_events_final_rows = []\n",
    "# for cells in special_events_rows:\n",
    "#     duration = int(cells[6].split(\":\")[0])\n",
    "#     for i in range(duration):\n",
    "#         if cells[7]==\"ALL\":\n",
    "#             for city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "#                 ser= []\n",
    "#                 hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "#                 ser.append(cells[4])\n",
    "#                 ser.append(hour)\n",
    "#                 ser.append(city)\n",
    "#                 ser.append(cells[0])\n",
    "#                 ser.append(cells[1])\n",
    "#                 ser.append(cells[2])\n",
    "#                 ser.append(cells[3])\n",
    "#                 special_events_final_rows.append(ser)\n",
    "#         else:\n",
    "#             ser= []\n",
    "#             city = cells[7]\n",
    "#             hour = str(int(cells[5].split(\":\")[0])+i)+\":00\"\n",
    "#             ser.append(cells[4])\n",
    "#             ser.append(hour)\n",
    "#             ser.append(city)\n",
    "#             ser.append(cells[0])\n",
    "#             ser.append(cells[1])\n",
    "#             ser.append(cells[2])\n",
    "#             ser.append(cells[3])\n",
    "#             special_events_final_rows.append(ser)\n",
    "            \n",
    "# special_events_df = pd.DataFrame(special_events_final_rows)\n",
    "# special_events_df.rename(columns={0:\"date_data\",1:\"hour_data\",2:\"city_code\",3:\"event_type\",4:\"event_category\",5:\"event_range\",6:\"event_impact\"},inplace=True)\n",
    "# football_matches_df = pd.DataFrame(football_matches_rows)\n",
    "# football_matches_df[\"match_range\"] = football_matches_df[\"match_range\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_range(x))\n",
    "# football_matches_df[\"match_type\"] = football_matches_df[\"match_type\"].apply(lambda x: 0 if str(x) == \"nan\" else encode_match_type(x))\n",
    "# football_matches_df.sort_values([\"date_data\",\"city_code\",\"hour_data\",\"match_range\",\"match_type\"], inplace=True, ascending=[True,True,True,False,False]) \n",
    "# football_matches_df.drop_duplicates(subset = [\"date_data\",\"hour_data\",\"city_code\"], keep = \"first\", inplace=True)\n",
    "# football_matches_df.rename(columns={0:\"date_data\",1:\"hour_data\",3:\"match_type\",2:\"match_range\",4:\"city_code\"},inplace=True)\n",
    "# final_df = pd.merge(football_matches_df,special_events_df,on=[\"date_data\",\"hour_data\",\"city_code\"],how=\"outer\")\n",
    "# final_df[\"date_data\"] = pd.to_datetime(final_df[\"date_data\"])\n",
    "# final_df[\"hour_data\"] = final_df[\"hour_data\"].apply(lambda x:encode_hour_data(x))\n",
    "# display(final_df)\n",
    "# final_df.to_csv(\"special_events_historical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9edadcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_data</th>\n",
       "      <th>hour_data</th>\n",
       "      <th>match_range</th>\n",
       "      <th>match_type</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>12:00</td>\n",
       "      <td>international</td>\n",
       "      <td>final</td>\n",
       "      <td>TIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>12:00</td>\n",
       "      <td>international</td>\n",
       "      <td>final</td>\n",
       "      <td>SFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>12:00</td>\n",
       "      <td>international</td>\n",
       "      <td>final</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>13:00</td>\n",
       "      <td>international</td>\n",
       "      <td>final</td>\n",
       "      <td>TIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>13:00</td>\n",
       "      <td>international</td>\n",
       "      <td>final</td>\n",
       "      <td>SFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>15:00</td>\n",
       "      <td>national</td>\n",
       "      <td>league</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>12:00</td>\n",
       "      <td>national</td>\n",
       "      <td>league</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>13:00</td>\n",
       "      <td>national</td>\n",
       "      <td>league</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>14:00</td>\n",
       "      <td>national</td>\n",
       "      <td>league</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>15:00</td>\n",
       "      <td>national</td>\n",
       "      <td>league</td>\n",
       "      <td>SOU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_data hour_data    match_range match_type city_code\n",
       "0    2022-11-22     12:00  international      final       TIS\n",
       "1    2022-11-22     12:00  international      final       SFX\n",
       "2    2022-11-22     12:00  international      final       SOU\n",
       "3    2022-11-22     13:00  international      final       TIS\n",
       "4    2022-11-22     13:00  international      final       SFX\n",
       "..          ...       ...            ...        ...       ...\n",
       "383  2022-12-25     15:00       national     league       SOU\n",
       "384  2022-12-30     12:00       national     league       SOU\n",
       "385  2022-12-30     13:00       national     league       SOU\n",
       "386  2022-12-30     14:00       national     league       SOU\n",
       "387  2022-12-30     15:00       national     league       SOU\n",
       "\n",
       "[388 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "football_matches_rows = []\n",
    "competetion_ids = {362: \"FIFA World Cup\",387 : \"EURO\", 227 : \"AFCON\", 244 : \"CL\",245 : \"EL\" , 223:\"ACL\",1 : \"bundesliga\",\n",
    "                  2:\"premier league\",3:\"laliga\",4:\"serieA\",5:\"ligue 1\",427:\"tunisia cup\",42:\"tunisia league\"}\n",
    "\n",
    "for competetion_id in list(competetion_ids.keys()) :\n",
    "    lll=requests.get(\"http://livescore-api.com/api-client/scores/history.json?from=2022-11-01&competition_id=\"+str(competetion_id)+\"&key=ilfcBNNH7eyenwHH&secret=hfrVN6M8GP2S6sgpOwCpjp6rEFF2bnJt\")\n",
    "    ss = json.loads(lll.content)\n",
    "    for match in ss[\"data\"][\"match\"]:\n",
    "        mdate = match[\"date\"]\n",
    "        mhour = match[\"scheduled\"]\n",
    "        mteamh = match[\"home_name\"]\n",
    "        mteama = match[\"away_name\"]\n",
    "        match_date = mdate\n",
    "        if (mteamh in [\"Tunisia\",\"Brazil\",'Club Africain', 'CS Sfaxien', 'Manchester City','Real Madrid', 'Etoile du Sahel', 'Esperance']) or (mteama in [\"Tunisia\",\"Brazil\",'Club Africain', 'CS Sfaxien', 'Manchester City','Real Madrid', 'Etoile du Sahel', 'Esperance']):\n",
    "            if competetion_id in [362,381,227,244,245,223,427]:\n",
    "                match_range = \"international\"\n",
    "                city = \"ALL\"\n",
    "            else:\n",
    "                match_range = \"national\"\n",
    "                city = \"TIS\"\n",
    "\n",
    "            if competetion_id in [1,2,3,4,5,42] :\n",
    "                match_type = \"league\"   \n",
    "            elif competetion_id in [362,387,227,244,245,223,427] :\n",
    "                if True:\n",
    "                    match_type = \"final\"\n",
    "                else: \n",
    "                    match_type = \"cup\"   \n",
    "\n",
    "            for i in range(-1,3,1):\n",
    "                if city ==\"ALL\":\n",
    "                    for match_city in [\"TIS\",\"SFX\",\"SOU\"]:\n",
    "                        football_matches_row = []\n",
    "                        football_matches_row.append(match_date)\n",
    "                        football_matches_row.append(str(int(mhour.split(\":\")[0])+i)+\":00\")\n",
    "                        football_matches_row.append(match_range)\n",
    "                        football_matches_row.append(match_type)\n",
    "                        football_matches_row.append(match_city)\n",
    "                        football_matches_rows.append(football_matches_row)\n",
    "                else :\n",
    "                    football_matches_row = []\n",
    "                    football_matches_row.append(match_date)\n",
    "                    football_matches_row.append(str(int(mhour.split(\":\")[0])+i)+\":00\")\n",
    "                    football_matches_row.append(match_range)\n",
    "                    football_matches_row.append(match_type)\n",
    "                    football_matches_row.append(match_city)\n",
    "                    football_matches_rows.append(football_matches_row)\n",
    "\n",
    "    #         break\n",
    "\n",
    "\n",
    "football_matches_df = pd.DataFrame(football_matches_rows)\n",
    "football_matches_df.rename(columns={0:\"date_data\",1:\"hour_data\",3:\"match_type\",2:\"match_range\",4:\"city_code\",5:\"away\",6:\"home\"},inplace=True)\n",
    "display(football_matches_df)\n",
    "football_matches_df.to_csv(\"special_events_historical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51688568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# football_matches_df[\"away\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
